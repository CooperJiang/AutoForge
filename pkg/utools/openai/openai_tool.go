package openai

import (
	"auto-forge/pkg/config"
	"auto-forge/pkg/utools"
	"bytes"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"time"
)

// OpenAITool OpenAI ChatGPT å·¥å…·
type OpenAITool struct {
	*utools.BaseTool
}

// NewOpenAITool åˆ›å»º OpenAI å·¥å…·å®ä¾‹
func NewOpenAITool() *OpenAITool {
	metadata := &utools.ToolMetadata{
		Code:        "openai_chatgpt",
		Name:        "OpenAI Chat",
		Description: "ä½¿ç”¨ OpenAI Chat API è¿›è¡Œå¯¹è¯ï¼Œæ”¯æŒ GPT-3.5ã€GPT-4ã€GPT-4o ç­‰å¯¹è¯æ¨¡å‹",
		Category:    "ai",
		Version:     "1.0.0",
		Author:      "AutoForge",
		AICallable:  true,
		Tags:        []string{"openai", "chatgpt", "ai", "llm", "gpt", "chat"},
		OutputFieldsSchema: map[string]utools.OutputFieldDef{
			"response": {
				Type:  "object",
				Label: "â­ OpenAI å®Œæ•´åŸå§‹å“åº”ï¼ˆæ¨èä½¿ç”¨ï¼‰",
				Children: map[string]utools.OutputFieldDef{
					"id":      {Type: "string", Label: "å“åº”ID"},
					"object":  {Type: "string", Label: "å¯¹è±¡ç±»å‹"},
					"created": {Type: "number", Label: "åˆ›å»ºæ—¶é—´æˆ³"},
					"model":   {Type: "string", Label: "ä½¿ç”¨çš„æ¨¡å‹"},
					"choices": {
						Type:  "array",
						Label: "å›å¤é€‰é¡¹æ•°ç»„",
						Children: map[string]utools.OutputFieldDef{
							"0": {
								Type:  "object",
								Label: "ç¬¬ä¸€ä¸ªå›å¤",
								Children: map[string]utools.OutputFieldDef{
									"index": {Type: "number", Label: "ç´¢å¼•"},
									"message": {
										Type:  "object",
										Label: "æ¶ˆæ¯å¯¹è±¡",
										Children: map[string]utools.OutputFieldDef{
											"role":    {Type: "string", Label: "è§’è‰²"},
											"content": {Type: "string", Label: "å›å¤å†…å®¹"},
										},
									},
									"finish_reason": {Type: "string", Label: "ç»“æŸåŸå› "},
								},
							},
						},
					},
					"usage": {
						Type:  "object",
						Label: "Token ä½¿ç”¨æƒ…å†µ",
						Children: map[string]utools.OutputFieldDef{
							"prompt_tokens":     {Type: "number", Label: "æç¤ºè¯ Token æ•°"},
							"completion_tokens": {Type: "number", Label: "å›å¤ Token æ•°"},
							"total_tokens":      {Type: "number", Label: "æ€» Token æ•°"},
						},
					},
				},
			},
			"content":           {Type: "string", Label: "ğŸ’¡ å¿«æ·è®¿é—®ï¼šChatGPT å›å¤å†…å®¹"},
			"model":             {Type: "string", Label: "ğŸ’¡ å¿«æ·è®¿é—®ï¼šä½¿ç”¨çš„æ¨¡å‹"},
			"finish_reason":     {Type: "string", Label: "ğŸ’¡ å¿«æ·è®¿é—®ï¼šç»“æŸåŸå› "},
			"prompt_tokens":     {Type: "number", Label: "ğŸ’¡ å¿«æ·è®¿é—®ï¼šæç¤ºè¯ Token æ•°"},
			"completion_tokens": {Type: "number", Label: "ğŸ’¡ å¿«æ·è®¿é—®ï¼šå›å¤ Token æ•°"},
			"total_tokens":      {Type: "number", Label: "ğŸ’¡ å¿«æ·è®¿é—®ï¼šæ€» Token æ•°"},
			"prompt":            {Type: "string", Label: "ğŸ’¡ å¿«æ·è®¿é—®ï¼šåŸå§‹æç¤ºè¯"},
		},
	}

	schema := &utools.ConfigSchema{
		Type: "object",
		Properties: map[string]utools.PropertySchema{
			"model": {
				Type:        "string",
				Title:       "æ¨¡å‹",
				Description: "ä½¿ç”¨çš„å¯¹è¯æ¨¡å‹ï¼Œä¾‹å¦‚ï¼šgpt-3.5-turboã€gpt-4ã€gpt-4o ç­‰",
				Default:     "gpt-3.5-turbo",
			},
			"prompt": {
				Type:        "string",
				Title:       "æç¤ºè¯",
				Description: "å‘é€ç»™ AI çš„é—®é¢˜æˆ–æŒ‡ä»¤ï¼Œæ”¯æŒå˜é‡",
			},
			"system_message": {
				Type:        "string",
				Title:       "ç³»ç»Ÿæ¶ˆæ¯",
				Description: "ç³»ç»Ÿè§’è‰²æ¶ˆæ¯ï¼ˆå¯é€‰ï¼‰ï¼Œç”¨äºè®¾å®š AI çš„è¡Œä¸ºå’Œè§’è‰²",
			},
			"temperature": {
				Type:        "number",
				Title:       "æ¸©åº¦",
				Description: "æ§åˆ¶å›å¤çš„éšæœºæ€§ï¼Œ0-2 ä¹‹é—´ï¼Œè¶Šé«˜è¶Šéšæœº",
				Default:     0.7,
			},
			"max_tokens": {
				Type:        "number",
				Title:       "æœ€å¤§ Token æ•°",
				Description: "ç”Ÿæˆå›å¤çš„æœ€å¤§ token æ•°é‡ï¼ˆå¯é€‰ï¼‰",
			},
			"timeout": {
				Type:        "number",
				Title:       "è¶…æ—¶æ—¶é—´",
				Description: "API è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ 300 ç§’",
				Default:     300,
			},
		},
		Required: []string{"model", "prompt"},
	}

	return &OpenAITool{
		BaseTool: utools.NewBaseTool(metadata, schema),
	}
}

// Execute æ‰§è¡Œ ChatGPT è°ƒç”¨
func (t *OpenAITool) Execute(ctx *utools.ExecutionContext, toolConfig map[string]interface{}) (*utools.ExecutionResult, error) {
	startTime := time.Now()

	// ä»é…ç½®æ–‡ä»¶è¯»å– API å‡­è¯
	cfg := config.GetConfig()
	apiKey := cfg.OpenAI.APIKey
	if apiKey == "" {
		return &utools.ExecutionResult{
			Success:    false,
			Message:    "OpenAI API Key æœªé…ç½®ï¼Œè¯·åœ¨ config.yaml ä¸­é…ç½® openai.api_key",
			Error:      "missing openai api_key in config",
			DurationMs: time.Since(startTime).Milliseconds(),
		}, fmt.Errorf("openai api_key not configured")
	}

	apiBase := cfg.OpenAI.APIBase
	if apiBase == "" {
		apiBase = "https://api.openai.com/v1"
	}

	// ä»ç”¨æˆ·é…ç½®è·å–å‚æ•°
	model, _ := toolConfig["model"].(string)
	if model == "" {
		return &utools.ExecutionResult{
			Success:    false,
			Message:    "æ¨¡å‹ä¸èƒ½ä¸ºç©º",
			Error:      "missing model",
			DurationMs: time.Since(startTime).Milliseconds(),
		}, fmt.Errorf("model is required")
	}

	prompt, _ := toolConfig["prompt"].(string)
	if prompt == "" {
		return &utools.ExecutionResult{
			Success:    false,
			Message:    "æç¤ºè¯ä¸èƒ½ä¸ºç©º",
			Error:      "missing prompt",
			DurationMs: time.Since(startTime).Milliseconds(),
		}, fmt.Errorf("prompt is required")
	}

	systemMessage, _ := toolConfig["system_message"].(string)
	temperature := 0.7
	if temp, ok := toolConfig["temperature"].(float64); ok {
		temperature = temp
	}

	// è¶…æ—¶æ—¶é—´ï¼Œé»˜è®¤ 300 ç§’
	timeout := 300
	if t, ok := toolConfig["timeout"].(float64); ok && t > 0 {
		timeout = int(t)
	}

	// æ„å»ºæ¶ˆæ¯
	messages := []map[string]interface{}{}

	if systemMessage != "" {
		messages = append(messages, map[string]interface{}{
			"role":    "system",
			"content": systemMessage,
		})
	}

	messages = append(messages, map[string]interface{}{
		"role":    "user",
		"content": prompt,
	})

	// æ„å»ºè¯·æ±‚ä½“
	requestBody := map[string]interface{}{
		"model":       model,
		"messages":    messages,
		"temperature": temperature,
	}

	if maxTokens, ok := toolConfig["max_tokens"].(float64); ok && maxTokens > 0 {
		requestBody["max_tokens"] = int(maxTokens)
	}

	jsonData, err := json.Marshal(requestBody)
	if err != nil {
		return &utools.ExecutionResult{
			Success:    false,
			Message:    "æ„å»ºè¯·æ±‚å¤±è´¥",
			Error:      err.Error(),
			DurationMs: time.Since(startTime).Milliseconds(),
		}, err
	}

	// å‘é€è¯·æ±‚
	url := fmt.Sprintf("%s/chat/completions", apiBase)
	req, err := http.NewRequest("POST", url, bytes.NewBuffer(jsonData))
	if err != nil {
		return &utools.ExecutionResult{
			Success:    false,
			Message:    "åˆ›å»ºè¯·æ±‚å¤±è´¥",
			Error:      err.Error(),
			DurationMs: time.Since(startTime).Milliseconds(),
		}, err
	}

	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Authorization", fmt.Sprintf("Bearer %s", apiKey))

	client := &http.Client{
		Timeout: time.Duration(timeout) * time.Second,
	}

	resp, err := client.Do(req)
	if err != nil {
		return &utools.ExecutionResult{
			Success:    false,
			Message:    "API è¯·æ±‚å¤±è´¥",
			Error:      err.Error(),
			DurationMs: time.Since(startTime).Milliseconds(),
		}, err
	}
	defer resp.Body.Close()

	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return &utools.ExecutionResult{
			Success:    false,
			Message:    "è¯»å–å“åº”å¤±è´¥",
			Error:      err.Error(),
			DurationMs: time.Since(startTime).Milliseconds(),
		}, err
	}

	// è§£æå“åº”
	var result map[string]interface{}
	if err := json.Unmarshal(body, &result); err != nil {
		return &utools.ExecutionResult{
			Success:    false,
			Message:    "è§£æå“åº”å¤±è´¥",
			Error:      err.Error(),
			Output:     map[string]interface{}{"raw_response": string(body)},
			DurationMs: time.Since(startTime).Milliseconds(),
		}, err
	}

	// æ£€æŸ¥ HTTP çŠ¶æ€ç 
	if resp.StatusCode != 200 {
		errorMsg := fmt.Sprintf("HTTP %d", resp.StatusCode)
		if errorObj, ok := result["error"].(map[string]interface{}); ok {
			if msg, ok := errorObj["message"].(string); ok {
				errorMsg = msg
			}
		}
		return &utools.ExecutionResult{
			Success:    false,
			Message:    fmt.Sprintf("OpenAI API é”™è¯¯: %s", errorMsg),
			Error:      errorMsg,
			Output:     result,
			DurationMs: time.Since(startTime).Milliseconds(),
		}, fmt.Errorf("openai api error: %s", errorMsg)
	}

	// æ£€æŸ¥é”™è¯¯
	if errorObj, ok := result["error"].(map[string]interface{}); ok {
		errorMsg, _ := errorObj["message"].(string)
		errorType, _ := errorObj["type"].(string)
		return &utools.ExecutionResult{
			Success:    false,
			Message:    fmt.Sprintf("OpenAI API é”™è¯¯: %s", errorMsg),
			Error:      errorType,
			Output:     result,
			DurationMs: time.Since(startTime).Milliseconds(),
		}, fmt.Errorf("openai api error: %s", errorMsg)
	}

	// æå–å›å¤å†…å®¹
	choices, ok := result["choices"].([]interface{})
	if !ok || len(choices) == 0 {
		return &utools.ExecutionResult{
			Success:    false,
			Message:    "OpenAI API è¿”å›æ ¼å¼å¼‚å¸¸ï¼šæœªæ‰¾åˆ° choices å­—æ®µ",
			Error:      "no choices in response",
			Output: map[string]interface{}{
				"raw_response": result,
				"status_code":  resp.StatusCode,
			},
			DurationMs: time.Since(startTime).Milliseconds(),
		}, fmt.Errorf("no choices in response, raw: %v", result)
	}

	// æå–æ¶ˆæ¯å†…å®¹ï¼Œä¾¿äºåç»­èŠ‚ç‚¹å¼•ç”¨
	content := ""
	if len(choices) > 0 {
		if choice, ok := choices[0].(map[string]interface{}); ok {
			if message, ok := choice["message"].(map[string]interface{}); ok {
				if c, ok := message["content"].(string); ok {
					content = c
				}
			}
		}
	}

	return &utools.ExecutionResult{
		Success: true,
		Message: "ChatGPT è°ƒç”¨æˆåŠŸ",
		Output: map[string]interface{}{
			"response": result, // OpenAI åŸå§‹å®Œæ•´å“åº”
			"content":  content, // ä¾¿æ·å­—æ®µï¼šç›´æ¥è®¿é—®è¿”å›çš„æ–‡æœ¬å†…å®¹
		},
		DurationMs: time.Since(startTime).Milliseconds(),
	}, nil
}

// init è‡ªåŠ¨æ³¨å†Œå·¥å…·
func init() {
	tool := NewOpenAITool()
	if err := utools.Register(tool); err != nil {
		panic(fmt.Sprintf("Failed to register OpenAI tool: %v", err))
	}
}
